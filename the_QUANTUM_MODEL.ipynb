{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbXS2Fqy57RuQv6y6cnLoA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Callmerakha/Quantum-Computing-Project/blob/main/the_QUANTUM_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QCNN in QUANTUM COMPUTING\n",
        "\n",
        "based on claude.ai\n",
        "https://claude.ai/chat/f44e306e-c422-4ab5-ad85-ebee75ee27d0"
      ],
      "metadata": {
        "id": "LSwKMyoa6j0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meginstall Qiskit dan beberapa keperluan lain untuk QCNN"
      ],
      "metadata": {
        "id": "o0YXS6ewOOWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_xvhZJRrOFP",
        "outputId": "f8b22f16-3693-4fb4-b369-2a47dbf71345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-1.2.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.38.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting pennylane-qiskit\n",
            "  Downloading PennyLane_qiskit-0.38.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.3)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.6.12-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.38 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.1)\n",
            "Collecting qiskit-aer (from pennylane-qiskit)\n",
            "  Downloading qiskit_aer-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting qiskit-ibm-runtime<=0.29 (from pennylane-qiskit)\n",
            "  Downloading qiskit_ibm_runtime-0.29.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting qiskit-ibm-provider (from pennylane-qiskit)\n",
            "  Downloading qiskit_ibm_provider-0.11.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting sympy>=1.3 (from qiskit)\n",
            "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Collecting requests-ntlm>=1.1.0 (from qiskit-ibm-runtime<=0.29->pennylane-qiskit)\n",
            "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.2.3)\n",
            "Requirement already satisfied: websocket-client>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (1.8.0)\n",
            "Collecting ibm-platform-services>=0.22.6 (from qiskit-ibm-runtime<=0.29->pennylane-qiskit)\n",
            "  Downloading ibm_platform_services-0.57.2-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: pydantic>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.9.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer->pennylane-qiskit) (5.9.5)\n",
            "Collecting websockets>=10.0 (from qiskit-ibm-provider->pennylane-qiskit)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting ibm-cloud-sdk-core<4.0.0,>=3.22.0 (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime<=0.29->pennylane-qiskit)\n",
            "  Downloading ibm_cloud_sdk_core-3.22.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.23.4)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.10/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (43.0.1)\n",
            "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit)\n",
            "  Downloading pyspnego-0.11.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from ibm-cloud-sdk-core<4.0.0,>=3.22.0->ibm-platform-services>=0.22.6->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.9.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.22)\n",
            "Downloading qiskit-1.2.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane-0.38.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_qiskit-0.38.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.6.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m758.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_ibm_runtime-0.29.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading qiskit_aer-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_ibm_provider-0.11.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_platform_services-0.57.2-py3-none-any.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_cloud_sdk_core-3.22.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyspnego-0.11.1-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, websockets, sympy, symengine, rustworkx, pbr, dill, autoray, stevedore, ibm-cloud-sdk-core, qiskit, pyspnego, ibm-platform-services, requests-ntlm, qiskit-aer, qiskit-ibm-runtime, qiskit-ibm-provider, pennylane-lightning, pennylane, pennylane-qiskit\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "Successfully installed appdirs-1.4.4 autoray-0.6.12 dill-0.3.9 ibm-cloud-sdk-core-3.22.0 ibm-platform-services-0.57.2 pbr-6.1.0 pennylane-0.38.0 pennylane-lightning-0.38.0 pennylane-qiskit-0.38.1 pyspnego-0.11.1 qiskit-1.2.4 qiskit-aer-0.15.1 qiskit-ibm-provider-0.11.0 qiskit-ibm-runtime-0.29.0 requests-ntlm-1.3.0 rustworkx-0.15.1 stevedore-5.3.0 symengine-0.13.0 sympy-1.12.1 websockets-13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit pennylane pennylane-qiskit torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mengengcek apakah sudah terintall dengan baik atau beluman dengang mengecek versinya"
      ],
      "metadata": {
        "id": "qqnSMuSdOW-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: grab the version\n",
        "\n",
        "import qiskit\n",
        "import pennylane\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib\n",
        "\n",
        "print(\"Qiskit version:\", qiskit.__version__)\n",
        "print(\"PennyLane version:\", pennylane.__version__)\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"Matplotlib version:\", matplotlib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzE1WgI-s5gt",
        "outputId": "34f49e9e-3929-4422-9af9-967b17925767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qiskit version: 1.2.4\n",
            "PennyLane version: 0.38.0\n",
            "Torch version: 2.4.1+cu121\n",
            "Torchvision version: 0.19.1+cu121\n",
            "Matplotlib version: 3.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan import"
      ],
      "metadata": {
        "id": "wjrSmiDXOltr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KbknVtKctJZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "proses inisiasi untuk encoding, convolution, dan pooling untuk data input oleh Quantum Circuit"
      ],
      "metadata": {
        "id": "JhnOMrf3O1Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    # Encoding\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(inputs[i], wires=i)\n",
        "\n",
        "    # Convolutional layer\n",
        "    for i in range(n_qubits):\n",
        "        qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
        "        qml.RY(weights[0, i], wires=(i+1)%n_qubits)\n",
        "\n",
        "    # Pooling layer\n",
        "    for i in range(0, n_qubits, 2):\n",
        "        qml.CNOT(wires=[i, i+1])\n",
        "        qml.RY(weights[1, i//2], wires=i+1)\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]"
      ],
      "metadata": {
        "id": "OxQWE7YztPcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "menggabungkan jaringan saraf klasik (menggunakan PyTorch) dengan sirkuit Quantum Neural Network (QNN) yang telah didefinisikan sebelumnya (qnode)"
      ],
      "metadata": {
        "id": "1c8maYwzPglL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pre_net = torch.nn.Linear(28*28, n_qubits)\n",
        "        self.q_params = torch.nn.Parameter(torch.randn(2, n_qubits//2))\n",
        "        self.post_net = torch.nn.Linear(n_qubits, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pre_net(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = qnode(x, self.q_params)\n",
        "        x = torch.tensor(x)\n",
        "        x = self.post_net(x)\n",
        "        return x\n",
        "\n",
        "model = HybridModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cuFA6XjGtSTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data preprocessing dan data loading yang digunakan untuk mengunduh, mempersiapkan, dan memuat dataset MNIST"
      ],
      "metadata": {
        "id": "W913kdEFPppW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKM8g42LtVeD",
        "outputId": "b4605a82-4225-4089-d5fc-6be01929b579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 52311165.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1739230.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 15378011.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2383401.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    # Encoding\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(inputs[i], wires=i)\n",
        "\n",
        "    # Convolutional layer\n",
        "    for i in range(n_qubits):\n",
        "        qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
        "        # Use weights with correct indexing\n",
        "        qml.RY(weights[0, i % (n_qubits//2)], wires=(i+1)%n_qubits)\n",
        "\n",
        "    # Pooling layer\n",
        "    for i in range(0, n_qubits, 2):\n",
        "        qml.CNOT(wires=[i, i+1])\n",
        "        # Use weights with correct indexing\n",
        "        qml.RY(weights[1, i//2], wires=i+1)\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]"
      ],
      "metadata": {
        "id": "M-McFmj2tXv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pre_net = torch.nn.Linear(28*28, n_qubits)\n",
        "        self.q_params = torch.nn.Parameter(torch.randn(2, n_qubits//2))\n",
        "        self.post_net = torch.nn.Linear(n_qubits, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = self.pre_net(x)\n",
        "        x = torch.tanh(x)\n",
        "\n",
        "        # Process each item in the batch\n",
        "        q_out = torch.zeros(batch_size, n_qubits)\n",
        "        for i in range(batch_size):\n",
        "            q_out[i] = torch.tensor(qnode(x[i], self.q_params), requires_grad=True)\n",
        "\n",
        "        x = self.post_net(q_out)\n",
        "        return x\n",
        "\n",
        "model = HybridModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cRJHUe8Etc50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING MODEL"
      ],
      "metadata": {
        "id": "wYh4KMjO3FuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Assuming the model definition and data loaders are already set up\n",
        "\n",
        "def train(model, train_loader, optimizer, loss_func, epochs=2):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            data = data.reshape(-1, 28*28)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = loss_func(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                      f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.4f}')\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            data = data.reshape(-1, 28*28)\n",
        "            output = model(data)\n",
        "            test_loss += loss_func(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n')\n",
        "    return accuracy\n",
        "\n",
        "# If you have access to a GPU, use it:\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, optimizer, loss_func)\n",
        "\n",
        "# Test the model\n",
        "test_accuracy = test(model, test_loader)\n",
        "print(f\"Final test accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB98ZG5SvHmY",
        "outputId": "4ff51a01-7109-45ba-ce06-aff70b5802fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.8002\n",
            "Train Epoch: 0 [400/60000 (1%)]\tLoss: 2.3671\n",
            "Train Epoch: 0 [800/60000 (1%)]\tLoss: 1.9975\n",
            "Train Epoch: 0 [1200/60000 (2%)]\tLoss: 2.2795\n",
            "Train Epoch: 0 [1600/60000 (3%)]\tLoss: 2.3730\n",
            "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 2.3535\n",
            "Train Epoch: 0 [2400/60000 (4%)]\tLoss: 2.5037\n",
            "Train Epoch: 0 [2800/60000 (5%)]\tLoss: 2.3401\n",
            "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 2.2818\n",
            "Train Epoch: 0 [3600/60000 (6%)]\tLoss: 2.2465\n",
            "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 2.2988\n",
            "Train Epoch: 0 [4400/60000 (7%)]\tLoss: 2.3166\n",
            "Train Epoch: 0 [4800/60000 (8%)]\tLoss: 2.3039\n",
            "Train Epoch: 0 [5200/60000 (9%)]\tLoss: 2.2866\n",
            "Train Epoch: 0 [5600/60000 (9%)]\tLoss: 2.1197\n",
            "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 2.3053\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.1840\n",
            "Train Epoch: 0 [6800/60000 (11%)]\tLoss: 2.1155\n",
            "Train Epoch: 0 [7200/60000 (12%)]\tLoss: 2.1111\n",
            "Train Epoch: 0 [7600/60000 (13%)]\tLoss: 2.0707\n",
            "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 2.0519\n",
            "Train Epoch: 0 [8400/60000 (14%)]\tLoss: 2.2592\n",
            "Train Epoch: 0 [8800/60000 (15%)]\tLoss: 2.1173\n",
            "Train Epoch: 0 [9200/60000 (15%)]\tLoss: 2.2305\n",
            "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 2.2121\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 2.2315\n",
            "Train Epoch: 0 [10400/60000 (17%)]\tLoss: 2.2522\n",
            "Train Epoch: 0 [10800/60000 (18%)]\tLoss: 2.2791\n",
            "Train Epoch: 0 [11200/60000 (19%)]\tLoss: 2.3321\n",
            "Train Epoch: 0 [11600/60000 (19%)]\tLoss: 2.2909\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 2.2033\n",
            "Train Epoch: 0 [12400/60000 (21%)]\tLoss: 2.1673\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.1453\n",
            "Train Epoch: 0 [13200/60000 (22%)]\tLoss: 2.2740\n",
            "Train Epoch: 0 [13600/60000 (23%)]\tLoss: 2.3396\n",
            "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 2.2828\n",
            "Train Epoch: 0 [14400/60000 (24%)]\tLoss: 2.2419\n",
            "Train Epoch: 0 [14800/60000 (25%)]\tLoss: 2.2587\n",
            "Train Epoch: 0 [15200/60000 (25%)]\tLoss: 2.3618\n",
            "Train Epoch: 0 [15600/60000 (26%)]\tLoss: 2.3719\n",
            "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 2.1393\n",
            "Train Epoch: 0 [16400/60000 (27%)]\tLoss: 2.1242\n",
            "Train Epoch: 0 [16800/60000 (28%)]\tLoss: 2.3309\n",
            "Train Epoch: 0 [17200/60000 (29%)]\tLoss: 2.2021\n",
            "Train Epoch: 0 [17600/60000 (29%)]\tLoss: 2.3007\n",
            "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 2.2644\n",
            "Train Epoch: 0 [18400/60000 (31%)]\tLoss: 2.3726\n",
            "Train Epoch: 0 [18800/60000 (31%)]\tLoss: 2.2375\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.1470\n",
            "Train Epoch: 0 [19600/60000 (33%)]\tLoss: 2.1331\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 2.2702\n",
            "Train Epoch: 0 [20400/60000 (34%)]\tLoss: 2.2836\n",
            "Train Epoch: 0 [20800/60000 (35%)]\tLoss: 2.1757\n",
            "Train Epoch: 0 [21200/60000 (35%)]\tLoss: 2.1650\n",
            "Train Epoch: 0 [21600/60000 (36%)]\tLoss: 2.2740\n",
            "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 1.9703\n",
            "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 2.1663\n",
            "Train Epoch: 0 [22800/60000 (38%)]\tLoss: 2.3787\n",
            "Train Epoch: 0 [23200/60000 (39%)]\tLoss: 1.9885\n",
            "Train Epoch: 0 [23600/60000 (39%)]\tLoss: 2.2876\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 2.2227\n",
            "Train Epoch: 0 [24400/60000 (41%)]\tLoss: 1.9420\n",
            "Train Epoch: 0 [24800/60000 (41%)]\tLoss: 2.3049\n",
            "Train Epoch: 0 [25200/60000 (42%)]\tLoss: 2.1760\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.2350\n",
            "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 2.4529\n",
            "Train Epoch: 0 [26400/60000 (44%)]\tLoss: 2.3209\n",
            "Train Epoch: 0 [26800/60000 (45%)]\tLoss: 2.1676\n",
            "Train Epoch: 0 [27200/60000 (45%)]\tLoss: 1.9513\n",
            "Train Epoch: 0 [27600/60000 (46%)]\tLoss: 2.2186\n",
            "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 2.1603\n",
            "Train Epoch: 0 [28400/60000 (47%)]\tLoss: 2.2992\n",
            "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 2.2975\n",
            "Train Epoch: 0 [29200/60000 (49%)]\tLoss: 2.0871\n",
            "Train Epoch: 0 [29600/60000 (49%)]\tLoss: 2.0136\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 2.1861\n",
            "Train Epoch: 0 [30400/60000 (51%)]\tLoss: 2.2456\n",
            "Train Epoch: 0 [30800/60000 (51%)]\tLoss: 2.1827\n",
            "Train Epoch: 0 [31200/60000 (52%)]\tLoss: 2.2640\n",
            "Train Epoch: 0 [31600/60000 (53%)]\tLoss: 2.1488\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.0704\n",
            "Train Epoch: 0 [32400/60000 (54%)]\tLoss: 1.9837\n",
            "Train Epoch: 0 [32800/60000 (55%)]\tLoss: 2.0132\n",
            "Train Epoch: 0 [33200/60000 (55%)]\tLoss: 2.1642\n",
            "Train Epoch: 0 [33600/60000 (56%)]\tLoss: 2.5246\n",
            "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 2.1779\n",
            "Train Epoch: 0 [34400/60000 (57%)]\tLoss: 2.2133\n",
            "Train Epoch: 0 [34800/60000 (58%)]\tLoss: 2.0808\n",
            "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 2.2808\n",
            "Train Epoch: 0 [35600/60000 (59%)]\tLoss: 2.1635\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 2.2506\n",
            "Train Epoch: 0 [36400/60000 (61%)]\tLoss: 2.2018\n",
            "Train Epoch: 0 [36800/60000 (61%)]\tLoss: 1.8548\n",
            "Train Epoch: 0 [37200/60000 (62%)]\tLoss: 2.1395\n",
            "Train Epoch: 0 [37600/60000 (63%)]\tLoss: 2.2208\n",
            "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 2.0507\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.3422\n",
            "Train Epoch: 0 [38800/60000 (65%)]\tLoss: 2.3113\n",
            "Train Epoch: 0 [39200/60000 (65%)]\tLoss: 2.1560\n",
            "Train Epoch: 0 [39600/60000 (66%)]\tLoss: 2.1070\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.8901\n",
            "Train Epoch: 0 [40400/60000 (67%)]\tLoss: 2.0979\n",
            "Train Epoch: 0 [40800/60000 (68%)]\tLoss: 2.3057\n",
            "Train Epoch: 0 [41200/60000 (69%)]\tLoss: 1.9604\n",
            "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 2.2317\n",
            "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 2.2756\n",
            "Train Epoch: 0 [42400/60000 (71%)]\tLoss: 2.0464\n",
            "Train Epoch: 0 [42800/60000 (71%)]\tLoss: 2.1844\n",
            "Train Epoch: 0 [43200/60000 (72%)]\tLoss: 2.4011\n",
            "Train Epoch: 0 [43600/60000 (73%)]\tLoss: 1.8956\n",
            "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 2.3285\n",
            "Train Epoch: 0 [44400/60000 (74%)]\tLoss: 1.8539\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 2.2557\n",
            "Train Epoch: 0 [45200/60000 (75%)]\tLoss: 2.3136\n",
            "Train Epoch: 0 [45600/60000 (76%)]\tLoss: 2.0383\n",
            "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 2.2776\n",
            "Train Epoch: 0 [46400/60000 (77%)]\tLoss: 2.4066\n",
            "Train Epoch: 0 [46800/60000 (78%)]\tLoss: 1.9120\n",
            "Train Epoch: 0 [47200/60000 (79%)]\tLoss: 2.2610\n",
            "Train Epoch: 0 [47600/60000 (79%)]\tLoss: 2.1115\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 2.2435\n",
            "Train Epoch: 0 [48400/60000 (81%)]\tLoss: 1.7801\n",
            "Train Epoch: 0 [48800/60000 (81%)]\tLoss: 2.0326\n",
            "Train Epoch: 0 [49200/60000 (82%)]\tLoss: 2.0795\n",
            "Train Epoch: 0 [49600/60000 (83%)]\tLoss: 2.1697\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 2.1661\n",
            "Train Epoch: 0 [50400/60000 (84%)]\tLoss: 2.1294\n",
            "Train Epoch: 0 [50800/60000 (85%)]\tLoss: 2.1539\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 1.9858\n",
            "Train Epoch: 0 [51600/60000 (86%)]\tLoss: 1.9185\n",
            "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 2.3264\n",
            "Train Epoch: 0 [52400/60000 (87%)]\tLoss: 2.0370\n",
            "Train Epoch: 0 [52800/60000 (88%)]\tLoss: 2.2191\n",
            "Train Epoch: 0 [53200/60000 (89%)]\tLoss: 2.3990\n",
            "Train Epoch: 0 [53600/60000 (89%)]\tLoss: 2.0395\n",
            "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 2.1094\n",
            "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 1.8822\n",
            "Train Epoch: 0 [54800/60000 (91%)]\tLoss: 2.3148\n",
            "Train Epoch: 0 [55200/60000 (92%)]\tLoss: 2.0184\n",
            "Train Epoch: 0 [55600/60000 (93%)]\tLoss: 2.0475\n",
            "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 1.9777\n",
            "Train Epoch: 0 [56400/60000 (94%)]\tLoss: 2.1895\n",
            "Train Epoch: 0 [56800/60000 (95%)]\tLoss: 2.2559\n",
            "Train Epoch: 0 [57200/60000 (95%)]\tLoss: 2.0956\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 2.3072\n",
            "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 2.0719\n",
            "Train Epoch: 0 [58400/60000 (97%)]\tLoss: 2.3248\n",
            "Train Epoch: 0 [58800/60000 (98%)]\tLoss: 1.9085\n",
            "Train Epoch: 0 [59200/60000 (99%)]\tLoss: 1.9751\n",
            "Train Epoch: 0 [59600/60000 (99%)]\tLoss: 2.2083\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.8870\n",
            "Train Epoch: 1 [400/60000 (1%)]\tLoss: 2.1300\n",
            "Train Epoch: 1 [800/60000 (1%)]\tLoss: 2.3684\n",
            "Train Epoch: 1 [1200/60000 (2%)]\tLoss: 2.3521\n",
            "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 1.9576\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 1.9266\n",
            "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 1.9759\n",
            "Train Epoch: 1 [2800/60000 (5%)]\tLoss: 2.3334\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.2247\n",
            "Train Epoch: 1 [3600/60000 (6%)]\tLoss: 2.5332\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.1088\n",
            "Train Epoch: 1 [4400/60000 (7%)]\tLoss: 2.3742\n",
            "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 1.6603\n",
            "Train Epoch: 1 [5200/60000 (9%)]\tLoss: 1.8772\n",
            "Train Epoch: 1 [5600/60000 (9%)]\tLoss: 2.0558\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.9295\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.2271\n",
            "Train Epoch: 1 [6800/60000 (11%)]\tLoss: 2.1686\n",
            "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 1.9753\n",
            "Train Epoch: 1 [7600/60000 (13%)]\tLoss: 2.2765\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.2245\n",
            "Train Epoch: 1 [8400/60000 (14%)]\tLoss: 2.0755\n",
            "Train Epoch: 1 [8800/60000 (15%)]\tLoss: 2.2872\n",
            "Train Epoch: 1 [9200/60000 (15%)]\tLoss: 1.8731\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.1017\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.1636\n",
            "Train Epoch: 1 [10400/60000 (17%)]\tLoss: 2.5775\n",
            "Train Epoch: 1 [10800/60000 (18%)]\tLoss: 2.1399\n",
            "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 2.0574\n",
            "Train Epoch: 1 [11600/60000 (19%)]\tLoss: 1.6661\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.3224\n",
            "Train Epoch: 1 [12400/60000 (21%)]\tLoss: 2.3122\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.0604\n",
            "Train Epoch: 1 [13200/60000 (22%)]\tLoss: 2.2334\n",
            "Train Epoch: 1 [13600/60000 (23%)]\tLoss: 2.0640\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.0106\n",
            "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 1.9224\n",
            "Train Epoch: 1 [14800/60000 (25%)]\tLoss: 2.4002\n",
            "Train Epoch: 1 [15200/60000 (25%)]\tLoss: 1.5946\n",
            "Train Epoch: 1 [15600/60000 (26%)]\tLoss: 1.9778\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.0088\n",
            "Train Epoch: 1 [16400/60000 (27%)]\tLoss: 2.1875\n",
            "Train Epoch: 1 [16800/60000 (28%)]\tLoss: 1.9821\n",
            "Train Epoch: 1 [17200/60000 (29%)]\tLoss: 1.7949\n",
            "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 2.2141\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.3510\n",
            "Train Epoch: 1 [18400/60000 (31%)]\tLoss: 2.3394\n",
            "Train Epoch: 1 [18800/60000 (31%)]\tLoss: 1.8836\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.3801\n",
            "Train Epoch: 1 [19600/60000 (33%)]\tLoss: 2.0791\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.4300\n",
            "Train Epoch: 1 [20400/60000 (34%)]\tLoss: 2.0391\n",
            "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 1.9214\n",
            "Train Epoch: 1 [21200/60000 (35%)]\tLoss: 1.9394\n",
            "Train Epoch: 1 [21600/60000 (36%)]\tLoss: 1.9488\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.1842\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.0226\n",
            "Train Epoch: 1 [22800/60000 (38%)]\tLoss: 1.8306\n",
            "Train Epoch: 1 [23200/60000 (39%)]\tLoss: 2.2724\n",
            "Train Epoch: 1 [23600/60000 (39%)]\tLoss: 2.1765\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.2695\n",
            "Train Epoch: 1 [24400/60000 (41%)]\tLoss: 2.2527\n",
            "Train Epoch: 1 [24800/60000 (41%)]\tLoss: 2.0395\n",
            "Train Epoch: 1 [25200/60000 (42%)]\tLoss: 2.1321\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.8684\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.1739\n",
            "Train Epoch: 1 [26400/60000 (44%)]\tLoss: 2.2412\n",
            "Train Epoch: 1 [26800/60000 (45%)]\tLoss: 1.8380\n",
            "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 1.9037\n",
            "Train Epoch: 1 [27600/60000 (46%)]\tLoss: 2.3425\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.1936\n",
            "Train Epoch: 1 [28400/60000 (47%)]\tLoss: 2.1902\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.2300\n",
            "Train Epoch: 1 [29200/60000 (49%)]\tLoss: 2.1073\n",
            "Train Epoch: 1 [29600/60000 (49%)]\tLoss: 1.8751\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.4320\n",
            "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 2.0038\n",
            "Train Epoch: 1 [30800/60000 (51%)]\tLoss: 2.1450\n",
            "Train Epoch: 1 [31200/60000 (52%)]\tLoss: 2.1677\n",
            "Train Epoch: 1 [31600/60000 (53%)]\tLoss: 1.9485\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.9188\n",
            "Train Epoch: 1 [32400/60000 (54%)]\tLoss: 1.5715\n",
            "Train Epoch: 1 [32800/60000 (55%)]\tLoss: 2.5006\n",
            "Train Epoch: 1 [33200/60000 (55%)]\tLoss: 1.8716\n",
            "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 1.9699\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.0642\n",
            "Train Epoch: 1 [34400/60000 (57%)]\tLoss: 2.0315\n",
            "Train Epoch: 1 [34800/60000 (58%)]\tLoss: 2.2029\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.5614\n",
            "Train Epoch: 1 [35600/60000 (59%)]\tLoss: 2.1772\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 1.9258\n",
            "Train Epoch: 1 [36400/60000 (61%)]\tLoss: 2.3221\n",
            "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 1.8372\n",
            "Train Epoch: 1 [37200/60000 (62%)]\tLoss: 2.2120\n",
            "Train Epoch: 1 [37600/60000 (63%)]\tLoss: 2.0966\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 1.8504\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.6037\n",
            "Train Epoch: 1 [38800/60000 (65%)]\tLoss: 2.4452\n",
            "Train Epoch: 1 [39200/60000 (65%)]\tLoss: 2.3179\n",
            "Train Epoch: 1 [39600/60000 (66%)]\tLoss: 1.7664\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.0817\n",
            "Train Epoch: 1 [40400/60000 (67%)]\tLoss: 2.1410\n",
            "Train Epoch: 1 [40800/60000 (68%)]\tLoss: 1.9013\n",
            "Train Epoch: 1 [41200/60000 (69%)]\tLoss: 2.2607\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.8084\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.2687\n",
            "Train Epoch: 1 [42400/60000 (71%)]\tLoss: 2.4738\n",
            "Train Epoch: 1 [42800/60000 (71%)]\tLoss: 2.2778\n",
            "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 2.0625\n",
            "Train Epoch: 1 [43600/60000 (73%)]\tLoss: 2.4319\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.7292\n",
            "Train Epoch: 1 [44400/60000 (74%)]\tLoss: 2.4498\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.1908\n",
            "Train Epoch: 1 [45200/60000 (75%)]\tLoss: 1.6202\n",
            "Train Epoch: 1 [45600/60000 (76%)]\tLoss: 1.8952\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.0414\n",
            "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 1.9235\n",
            "Train Epoch: 1 [46800/60000 (78%)]\tLoss: 2.0748\n",
            "Train Epoch: 1 [47200/60000 (79%)]\tLoss: 2.0994\n",
            "Train Epoch: 1 [47600/60000 (79%)]\tLoss: 1.7441\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.9776\n",
            "Train Epoch: 1 [48400/60000 (81%)]\tLoss: 2.2508\n",
            "Train Epoch: 1 [48800/60000 (81%)]\tLoss: 1.8998\n",
            "Train Epoch: 1 [49200/60000 (82%)]\tLoss: 2.1373\n",
            "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 2.1690\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.3126\n",
            "Train Epoch: 1 [50400/60000 (84%)]\tLoss: 2.3329\n",
            "Train Epoch: 1 [50800/60000 (85%)]\tLoss: 1.7493\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.2800\n",
            "Train Epoch: 1 [51600/60000 (86%)]\tLoss: 2.0685\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.1322\n",
            "Train Epoch: 1 [52400/60000 (87%)]\tLoss: 2.4429\n",
            "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 2.1360\n",
            "Train Epoch: 1 [53200/60000 (89%)]\tLoss: 1.7456\n",
            "Train Epoch: 1 [53600/60000 (89%)]\tLoss: 2.2076\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.4363\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 2.2401\n",
            "Train Epoch: 1 [54800/60000 (91%)]\tLoss: 2.0719\n",
            "Train Epoch: 1 [55200/60000 (92%)]\tLoss: 2.0945\n",
            "Train Epoch: 1 [55600/60000 (93%)]\tLoss: 2.3131\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.5761\n",
            "Train Epoch: 1 [56400/60000 (94%)]\tLoss: 2.2181\n",
            "Train Epoch: 1 [56800/60000 (95%)]\tLoss: 2.0986\n",
            "Train Epoch: 1 [57200/60000 (95%)]\tLoss: 2.7042\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.2820\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.2779\n",
            "Train Epoch: 1 [58400/60000 (97%)]\tLoss: 1.9298\n",
            "Train Epoch: 1 [58800/60000 (98%)]\tLoss: 1.9065\n",
            "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 1.9726\n",
            "Train Epoch: 1 [59600/60000 (99%)]\tLoss: 1.9374\n",
            "\n",
            "Test set: Average loss: 0.5061, Accuracy: 2847/10000 (28.47%)\n",
            "\n",
            "Final test accuracy: 28.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "setelah proses yang amat panjang dalam train ini.. kemudian akan dilakukan proses untuk mengecek sebarapa besar akurasinya dan melakukan visualisasi"
      ],
      "metadata": {
        "id": "pdIHGHiA2ptU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PROSES EVALUASI HASIL PREDIKSI"
      ],
      "metadata": {
        "id": "5eTgEnBJ2z2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def visualize_predictions(model, test_loader, num_images=5):\n",
        "    model.eval()\n",
        "    images, labels = next(iter(test_loader))\n",
        "    images = images[:num_images]\n",
        "    labels = labels[:num_images]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        images = images.to(device)\n",
        "        outputs = model(images.view(images.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "    for i, (image, label, prediction) in enumerate(zip(images, labels, predicted)):\n",
        "        axes[i].imshow(image.cpu().squeeze(), cmap='gray')\n",
        "        axes[i].set_title(f\"True: {label.item()}\\nPred: {prediction.item()}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage\n",
        "visualize_predictions(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "zre7S5YlXjRO",
        "outputId": "27a08efa-8a38-4da3-e6e8-4cfd9aef90f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah melakukan uji coba dengan melakukan visualisasi dan beberapa test lainnya.. kemudian model kami simpan dengan nama \"qcnn_mnist_model.pth\""
      ],
      "metadata": {
        "id": "iO6RR7ds2L0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'qcnn_mnist_model.pth')"
      ],
      "metadata": {
        "id": "A4TeNny82IEj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "683a443e-5bd5-4c05-9806-b261f56746fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9c7881586efe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'qcnn_mnist_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    }
  ]
}